{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:01:58.161911Z",
     "start_time": "2025-09-13T17:01:57.920166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "from csv import DictReader, DictWriter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "id": "d0052743fe1215e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:02:02.404254Z",
     "start_time": "2025-09-13T17:01:59.059766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_column_names = ['station_id', 'longitude', 'latitude', 'time', 'AtmospherePressure', 'WindDirection', 'WindSpeed', 'Gust', 'WaveHeight', 'WavePeriod', 'MeanWaveDirection', 'Hmax', 'AirTemperature', 'DewPoint', 'SeaTemperature', 'RelativeHumidity']\n",
    "\n",
    "new_column_names = ['AtmospherePressure', 'WindDirection', 'WindSpeed', 'Gust', 'AirTemperature', 'SeaTemperature', 'RelativeHumidity', 'WaveHeight', 'WavePeriod']\n",
    "\n",
    "with open('../data/raw_data.csv', 'r') as f1, open('../data/interim_data.csv', 'w') as f2:\n",
    "    reader = DictReader(f1, fieldnames=original_column_names)\n",
    "    writer = DictWriter(f2, fieldnames=new_column_names, lineterminator='\\n')\n",
    "\n",
    "    next(reader)\n",
    "    next(reader)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for line in tqdm(reader):\n",
    "        if any(line[column_name] == 'NaN' for column_name in new_column_names):\n",
    "            continue\n",
    "        writer.writerow({column_name: line[column_name] for column_name in new_column_names})\n"
   ],
   "id": "fc7dcb1475ef388d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "613392it [00:03, 183941.44it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:36:38.185069Z",
     "start_time": "2025-09-13T17:36:38.004584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/interim_data.csv')\n",
    "df.shape"
   ],
   "id": "a11ec7e8daab22c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385474, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T19:33:20.572276Z",
     "start_time": "2025-09-13T19:33:19.339156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the interquartile range to remove the outliers in data.\n",
    "for column_name in new_column_names:\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_whisker = Q1 - 1.5*IQR\n",
    "    upper_whisker = Q3 + 1.5*IQR\n",
    "    df = df[(df[column_name] >= lower_whisker) & (df[column_name] <= upper_whisker)]\n",
    "\n",
    "\n",
    "df.to_csv('../data/processed_data.csv', index=False)"
   ],
   "id": "effb0299530afe7e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1a0f66e4de8fba7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
